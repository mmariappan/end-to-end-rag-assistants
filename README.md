# ğŸ“š RAG PDF Chat Assistant

> **AI-powered PDF chat assistant** using Retrieval-Augmented Generation (RAG), ChromaDB, and OpenAI GPT models.  
> Upload PDFs, ask natural-language questions, and get **accurate, source-grounded answers** â€” all with full context visibility.

---

## ğŸŒŸ Overview

RAG PDF Chat Assistant combines **semantic search** and **large language models** to help you intelligently query and understand PDF documents.  
It extracts, chunks, embeds, and stores document text for fast, context-aware retrieval and question answering.

### Key Highlights

- ğŸ“„ **PDF Processing** â€“ Text extraction and chunking via PyMuPDF + NLTK
- ğŸ” **Semantic Search** â€“ 768-dim embeddings with SentenceTransformers
- ğŸ’¾ **ChromaDB Storage** â€“ Persistent, deduplicated vector database
- ğŸ¤– **AI-Powered Q&A** â€“ Contextual responses from OpenAI GPT models
- ğŸ” **Transparency** â€“ Shows retrieved chunks and similarity scores
- âš¡ **Fast** â€“ Retrieves context in milliseconds

**Perfect for:** researchers, students, lawyers, analysts, and anyone managing large document collections.

---

## âœ¨ Core Features

### ğŸ“¤ PDF Upload & Processing

- Streamlit-based drag-and-drop interface
- Automatic extraction, chunking, and embedding
- Real-time progress and summary statistics

### ğŸ” Smart Deduplication

- File- and chunk-level SHA-256 hashing
- Avoids duplicate storage across revisions
- Saves 40â€“60 % storage on repeated uploads

### ğŸ” Semantic Search

- Uses `all-mpnet-base-v2` embeddings
- Cosine-similarity retrieval (Top-K configurable)

### ğŸ¤– AI-Powered Q&A

- Models: `gpt-4o-mini`, `gpt-4o`, `gpt-4-turbo`
- Temperature = 0.2 for factual answers
- Automatic context-building and prompt expansion

---

## ğŸ—ï¸ Architecture

![RAG PDF Chat Architecture](RAG_PDF_Chat_Architecture.png)

| Component                | Description                          |
| ------------------------ | ------------------------------------ |
| **Streamlit UI**         | Web interface for upload & chat      |
| **ChatPDF Base**         | PDF parsing, chunking, deduplication |
| **RAGHelper**            | Query handling, GPT API calls        |
| **ChromaDB**             | Vector store for embeddings          |
| **SentenceTransformers** | Generates semantic embeddings        |

---

## âš™ï¸ Tech Stack

| Layer        | Technology                                 |
| ------------ | ------------------------------------------ |
| UI           | Streamlit                                  |
| Vector DB    | ChromaDB                                   |
| Embeddings   | SentenceTransformers (`all-mpnet-base-v2`) |
| LLM          | OpenAI GPT                                 |
| PDF          | PyMuPDF                                    |
| Tokenization | NLTK                                       |
| Hashing      | hashlib                                    |
| Config       | python-dotenv                              |
| Data         | pandas                                     |

---

## ğŸš€ Quick Start

### 1ï¸âƒ£ Install

```bash
git clone https://github.com/mmariappan/rag-pdf-chat-assistant.git
cd rag-pdf-chat-assistant
python -m venv venv && source venv/bin/activate
pip install -r requirements.txt
```

### 2ï¸âƒ£ Configure Environment

Create a `.env` file:

```bash
OPENAI_API_KEY=your_openai_api_key
TOKENIZERS_PARALLELISM=false
```

### 3ï¸âƒ£ Run the App

```bash
streamlit run app.py
```

Visit [http://localhost:8501](http://localhost:8501)

---

## ğŸ’¡ Usage

1. **Upload a PDF** â†’ itâ€™s automatically chunked and stored in ChromaDB
2. **Ask a Question** â†’ GPT model retrieves relevant context and answers
3. **Inspect Sources** â†’ see the exact text chunks used
4. **Re-upload Docs** â†’ deduplication skips previously processed content

---

## ğŸ§  Configuration

- **Model:** choose `gpt-4o-mini`, `gpt-4o`, or `gpt-4-turbo`
- **Top-K:** number of chunks to retrieve (default = 5)
- **Chunk Size:** adjustable in `chatpdf_base.py â†’ max_sentences`

---

## ğŸŒ Deployment

### Streamlit Cloud

1. Push repo to GitHub
2. Go to [share.streamlit.io](https://share.streamlit.io) â†’ â€œNew appâ€
3. Choose `app.py` as entry point
4. Add secret:
   ```toml
   OPENAI_API_KEY = "your_openai_api_key"
   ```

### Docker (optional)

```dockerfile
FROM python:3.10-slim
WORKDIR /app
COPY . .
RUN pip install -r requirements.txt
EXPOSE 8501
CMD ["streamlit", "run", "app.py"]
```

Run:

```bash
docker build -t rag-pdf-chat .
docker run -p 8501:8501 -e OPENAI_API_KEY=your_key rag-pdf-chat
```

---

## ğŸ§© Troubleshooting

| Issue                      | Solution                                              |
| -------------------------- | ----------------------------------------------------- |
| `OPENAI_API_KEY not found` | Add `.env` file                                       |
| NLTK error                 | `python -c "import nltk; nltk.download('punkt_tab')"` |
| ChromaDB lock              | Delete `chroma_db/` folder and restart                |
| Slow performance           | Lower `top_k` or use `gpt-4o-mini`                    |

---

## ğŸ¤ Contributing

1. Fork â†’ create a branch â†’ commit changes
2. Run tests (`pytest`) and format with `black *.py`
3. Submit a Pull Request ğŸš€

---

## ğŸ“„ License

**MIT License Â© 2024 Mohandas Mariappan**

---

## ğŸ‘¤ Author

Built with â¤ï¸ by **Mohandas Mariappan**

- ğŸ’¼ [LinkedIn](https://www.linkedin.com/in/sunmohandas/)
- ğŸŒ [GitHub @mmariappan](https://github.com/mmariappan)

---

**â­ Star this repo if you find it helpful!**
